{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1da3f92e-cc48-4c62-8c5d-b1bbeff83943",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStep Three: End-of-Day (EOD) Data Load\\nNow that you’ve preprocessed the incoming data from the exchange, you need to create the\\nfinal data format to store on the cloud. The cloud will also store historic exchange data, so\\nSpring Capital can look up any trading day and easily find historic data.\\nThis preprocessed data will be used in the following ETL process, as well as for adhoc user\\nqueries.\\nAt the end of the last step, you have created three partitions under output_dir. It’s easy to go\\nthrough them one by one and create corresponding datasets. Note that the target dataset\\nshould have the specific schema required by the partition.\\nLearning Objectives:\\nBy the end of this step, you will be able to…\\n● Create Spark DataFrames using Parquet files\\n● Perform data cleaning using Spark aggregation methods.\\n● Use cloud storage as output of Spark jobs.\\nPrerequisites:\\n- PySpark: read multiple Parquet files into a single DataFrame, transformations, write\\nDataFrame.\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Guided Capstone Step Three\n",
    "'''\n",
    "Step Three: End-of-Day (EOD) Data Load\n",
    "Now that you’ve preprocessed the incoming data from the exchange, you need to create the\n",
    "final data format to store on the cloud. The cloud will also store historic exchange data, so\n",
    "Spring Capital can look up any trading day and easily find historic data.\n",
    "This preprocessed data will be used in the following ETL process, as well as for adhoc user\n",
    "queries.\n",
    "At the end of the last step, you have created three partitions under output_dir. It’s easy to go\n",
    "through them one by one and create corresponding datasets. Note that the target dataset\n",
    "should have the specific schema required by the partition.\n",
    "Learning Objectives:\n",
    "By the end of this step, you will be able to…\n",
    "● Create Spark DataFrames using Parquet files\n",
    "● Perform data cleaning using Spark aggregation methods.\n",
    "● Use cloud storage as output of Spark jobs.\n",
    "Prerequisites:\n",
    "- PySpark: read multiple Parquet files into a single DataFrame, transformations, write\n",
    "DataFrame.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa53ab55-4641-412c-a56f-ac96b0074381",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bc583ae-137a-497e-b48b-970042d67042",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\n",
      "  Using cached findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
      "Using cached findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Collecting pyspark\n",
      "  Using cached pyspark-3.5.5-py2.py3-none-any.whl\n",
      "Collecting py4j==0.10.9.7 (from pyspark)\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.5.5\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark\n",
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3277ed9e-c742-4277-9589-3f6cccdab532",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"EOD Data Load\").getOrCreate()\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "525bfa59-6932-456e-acc1-28690432236b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3.1 Populate trade dataset\n",
    "# 3.1.1 Read Trade Partition Dataset From It’s Temporary Location\n",
    "# Set Spark Configuration for Azure Blob Storage\n",
    "storage_account_name = \"trial25\"\n",
    "storage_account_key = \"\"\n",
    "spark.conf.set(f\"fs.azure.account.key.{storage_account_name}.blob.core.windows.net\",storage_account_key)\n",
    "trade_location =\"wasbs://equity-data@trial25.blob.core.windows.net/output_dir/partition=T\"\n",
    "trade_common = spark.read.parquet(trade_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97389fe0-15d4-46b9-86c3-40a4265627b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3.1.2 Select The Necessary Columns For Trade Records\n",
    "# The temporary data that you get is associated with a common schema, fitting both trade and\n",
    "# quote events. Since you’re going to produce trade and quote data separately, you need to\n",
    "# remove unnecessary columns to save space\n",
    "trade = trade_common.select(\"trade_dt\", \"symbol\", \"exchange\", \"event_tm\",\n",
    "\"event_seq_nb\",\"arrival_tm\", \"trade_pr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e819aaf-8627-4b64-8648-8f118f5ee9c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|         arrival_tm|\n",
      "+-------------------+\n",
      "|2020-08-06 09:30:00|\n",
      "|2020-08-05 09:30:00|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trade.select(\"arrival_tm\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1356bc54-afe5-448f-acb8-1e099485d8a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>trade_dt</th><th>symbol</th><th>exchange</th><th>event_tm</th><th>event_seq_nb</th><th>arrival_tm</th><th>trade_pr</th></tr></thead><tbody><tr><td>2020-08-05</td><td>SYMA</td><td>NYSE</td><td>2020-08-05T10:37:21.581Z</td><td>10</td><td>2020-08-05T09:30:00Z</td><td>79.190000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMA</td><td>NYSE</td><td>2020-08-05T11:56:13.086Z</td><td>20</td><td>2020-08-05T09:30:00Z</td><td>76.490000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMA</td><td>NYSE</td><td>2020-08-05T13:09:12.493Z</td><td>30</td><td>2020-08-05T09:30:00Z</td><td>75.050000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMA</td><td>NYSE</td><td>2020-08-05T14:24:34.33Z</td><td>40</td><td>2020-08-05T09:30:00Z</td><td>78.430000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMA</td><td>NYSE</td><td>2020-08-05T15:31:56.932Z</td><td>50</td><td>2020-08-05T09:30:00Z</td><td>78.150000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMA</td><td>NYSE</td><td>2020-08-05T16:37:06.676Z</td><td>60</td><td>2020-08-05T09:30:00Z</td><td>79.190000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMA</td><td>NYSE</td><td>2020-08-05T17:49:22.23Z</td><td>70</td><td>2020-08-05T09:30:00Z</td><td>77.070000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMA</td><td>NYSE</td><td>2020-08-05T19:04:45.677Z</td><td>80</td><td>2020-08-05T09:30:00Z</td><td>75.480000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMA</td><td>NYSE</td><td>2020-08-05T20:21:09.752Z</td><td>90</td><td>2020-08-05T09:30:00Z</td><td>74.600000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMA</td><td>NYSE</td><td>2020-08-05T21:30:19.773Z</td><td>100</td><td>2020-08-05T09:30:00Z</td><td>77.790000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMB</td><td>NYSE</td><td>2020-08-05T10:43:54.198Z</td><td>10</td><td>2020-08-05T09:30:00Z</td><td>34.980000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMB</td><td>NYSE</td><td>2020-08-05T12:02:40.506Z</td><td>20</td><td>2020-08-05T09:30:00Z</td><td>33.180000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMB</td><td>NYSE</td><td>2020-08-05T13:10:45.361Z</td><td>30</td><td>2020-08-05T09:30:00Z</td><td>34.180000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMB</td><td>NYSE</td><td>2020-08-05T14:26:20.473Z</td><td>40</td><td>2020-08-05T09:30:00Z</td><td>36.510000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMB</td><td>NYSE</td><td>2020-08-05T15:31:43.643Z</td><td>50</td><td>2020-08-05T09:30:00Z</td><td>36.080000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMB</td><td>NYSE</td><td>2020-08-05T16:48:29.503Z</td><td>60</td><td>2020-08-05T09:30:00Z</td><td>35.760000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMB</td><td>NYSE</td><td>2020-08-05T18:02:11.213Z</td><td>70</td><td>2020-08-05T09:30:00Z</td><td>32.680000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMB</td><td>NYSE</td><td>2020-08-05T19:08:12.441Z</td><td>80</td><td>2020-08-05T09:30:00Z</td><td>34.270000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMB</td><td>NYSE</td><td>2020-08-05T20:17:22.625Z</td><td>90</td><td>2020-08-05T09:30:00Z</td><td>34.250000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMB</td><td>NYSE</td><td>2020-08-05T21:27:28.314Z</td><td>100</td><td>2020-08-05T09:30:00Z</td><td>33.960000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMC</td><td>NYSE</td><td>2020-08-05T10:44:56.492Z</td><td>10</td><td>2020-08-05T09:30:00Z</td><td>160.880000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMC</td><td>NYSE</td><td>2020-08-05T11:58:06.861Z</td><td>20</td><td>2020-08-05T09:30:00Z</td><td>157.030000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMC</td><td>NYSE</td><td>2020-08-05T13:10:55.919Z</td><td>30</td><td>2020-08-05T09:30:00Z</td><td>157.250000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMC</td><td>NYSE</td><td>2020-08-05T14:32:26.063Z</td><td>40</td><td>2020-08-05T09:30:00Z</td><td>160.940000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMC</td><td>NYSE</td><td>2020-08-05T15:48:06.73Z</td><td>50</td><td>2020-08-05T09:30:00Z</td><td>159.170000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMC</td><td>NYSE</td><td>2020-08-05T17:01:38.379Z</td><td>60</td><td>2020-08-05T09:30:00Z</td><td>161.150000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMC</td><td>NYSE</td><td>2020-08-05T18:20:43.709Z</td><td>70</td><td>2020-08-05T09:30:00Z</td><td>158.180000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMC</td><td>NYSE</td><td>2020-08-05T19:37:55.659Z</td><td>80</td><td>2020-08-05T09:30:00Z</td><td>161.130000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMC</td><td>NYSE</td><td>2020-08-05T20:48:19.795Z</td><td>90</td><td>2020-08-05T09:30:00Z</td><td>159.720000000000000000</td></tr><tr><td>2020-08-05</td><td>SYMC</td><td>NYSE</td><td>2020-08-05T21:52:38.607Z</td><td>100</td><td>2020-08-05T09:30:00Z</td><td>160.620000000000000000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2020-08-05",
         "SYMA",
         "NYSE",
         "2020-08-05T10:37:21.581Z",
         10,
         "2020-08-05T09:30:00Z",
         "79.190000000000000000"
        ],
        [
         "2020-08-05",
         "SYMA",
         "NYSE",
         "2020-08-05T11:56:13.086Z",
         20,
         "2020-08-05T09:30:00Z",
         "76.490000000000000000"
        ],
        [
         "2020-08-05",
         "SYMA",
         "NYSE",
         "2020-08-05T13:09:12.493Z",
         30,
         "2020-08-05T09:30:00Z",
         "75.050000000000000000"
        ],
        [
         "2020-08-05",
         "SYMA",
         "NYSE",
         "2020-08-05T14:24:34.33Z",
         40,
         "2020-08-05T09:30:00Z",
         "78.430000000000000000"
        ],
        [
         "2020-08-05",
         "SYMA",
         "NYSE",
         "2020-08-05T15:31:56.932Z",
         50,
         "2020-08-05T09:30:00Z",
         "78.150000000000000000"
        ],
        [
         "2020-08-05",
         "SYMA",
         "NYSE",
         "2020-08-05T16:37:06.676Z",
         60,
         "2020-08-05T09:30:00Z",
         "79.190000000000000000"
        ],
        [
         "2020-08-05",
         "SYMA",
         "NYSE",
         "2020-08-05T17:49:22.23Z",
         70,
         "2020-08-05T09:30:00Z",
         "77.070000000000000000"
        ],
        [
         "2020-08-05",
         "SYMA",
         "NYSE",
         "2020-08-05T19:04:45.677Z",
         80,
         "2020-08-05T09:30:00Z",
         "75.480000000000000000"
        ],
        [
         "2020-08-05",
         "SYMA",
         "NYSE",
         "2020-08-05T20:21:09.752Z",
         90,
         "2020-08-05T09:30:00Z",
         "74.600000000000000000"
        ],
        [
         "2020-08-05",
         "SYMA",
         "NYSE",
         "2020-08-05T21:30:19.773Z",
         100,
         "2020-08-05T09:30:00Z",
         "77.790000000000000000"
        ],
        [
         "2020-08-05",
         "SYMB",
         "NYSE",
         "2020-08-05T10:43:54.198Z",
         10,
         "2020-08-05T09:30:00Z",
         "34.980000000000000000"
        ],
        [
         "2020-08-05",
         "SYMB",
         "NYSE",
         "2020-08-05T12:02:40.506Z",
         20,
         "2020-08-05T09:30:00Z",
         "33.180000000000000000"
        ],
        [
         "2020-08-05",
         "SYMB",
         "NYSE",
         "2020-08-05T13:10:45.361Z",
         30,
         "2020-08-05T09:30:00Z",
         "34.180000000000000000"
        ],
        [
         "2020-08-05",
         "SYMB",
         "NYSE",
         "2020-08-05T14:26:20.473Z",
         40,
         "2020-08-05T09:30:00Z",
         "36.510000000000000000"
        ],
        [
         "2020-08-05",
         "SYMB",
         "NYSE",
         "2020-08-05T15:31:43.643Z",
         50,
         "2020-08-05T09:30:00Z",
         "36.080000000000000000"
        ],
        [
         "2020-08-05",
         "SYMB",
         "NYSE",
         "2020-08-05T16:48:29.503Z",
         60,
         "2020-08-05T09:30:00Z",
         "35.760000000000000000"
        ],
        [
         "2020-08-05",
         "SYMB",
         "NYSE",
         "2020-08-05T18:02:11.213Z",
         70,
         "2020-08-05T09:30:00Z",
         "32.680000000000000000"
        ],
        [
         "2020-08-05",
         "SYMB",
         "NYSE",
         "2020-08-05T19:08:12.441Z",
         80,
         "2020-08-05T09:30:00Z",
         "34.270000000000000000"
        ],
        [
         "2020-08-05",
         "SYMB",
         "NYSE",
         "2020-08-05T20:17:22.625Z",
         90,
         "2020-08-05T09:30:00Z",
         "34.250000000000000000"
        ],
        [
         "2020-08-05",
         "SYMB",
         "NYSE",
         "2020-08-05T21:27:28.314Z",
         100,
         "2020-08-05T09:30:00Z",
         "33.960000000000000000"
        ],
        [
         "2020-08-05",
         "SYMC",
         "NYSE",
         "2020-08-05T10:44:56.492Z",
         10,
         "2020-08-05T09:30:00Z",
         "160.880000000000000000"
        ],
        [
         "2020-08-05",
         "SYMC",
         "NYSE",
         "2020-08-05T11:58:06.861Z",
         20,
         "2020-08-05T09:30:00Z",
         "157.030000000000000000"
        ],
        [
         "2020-08-05",
         "SYMC",
         "NYSE",
         "2020-08-05T13:10:55.919Z",
         30,
         "2020-08-05T09:30:00Z",
         "157.250000000000000000"
        ],
        [
         "2020-08-05",
         "SYMC",
         "NYSE",
         "2020-08-05T14:32:26.063Z",
         40,
         "2020-08-05T09:30:00Z",
         "160.940000000000000000"
        ],
        [
         "2020-08-05",
         "SYMC",
         "NYSE",
         "2020-08-05T15:48:06.73Z",
         50,
         "2020-08-05T09:30:00Z",
         "159.170000000000000000"
        ],
        [
         "2020-08-05",
         "SYMC",
         "NYSE",
         "2020-08-05T17:01:38.379Z",
         60,
         "2020-08-05T09:30:00Z",
         "161.150000000000000000"
        ],
        [
         "2020-08-05",
         "SYMC",
         "NYSE",
         "2020-08-05T18:20:43.709Z",
         70,
         "2020-08-05T09:30:00Z",
         "158.180000000000000000"
        ],
        [
         "2020-08-05",
         "SYMC",
         "NYSE",
         "2020-08-05T19:37:55.659Z",
         80,
         "2020-08-05T09:30:00Z",
         "161.130000000000000000"
        ],
        [
         "2020-08-05",
         "SYMC",
         "NYSE",
         "2020-08-05T20:48:19.795Z",
         90,
         "2020-08-05T09:30:00Z",
         "159.720000000000000000"
        ],
        [
         "2020-08-05",
         "SYMC",
         "NYSE",
         "2020-08-05T21:52:38.607Z",
         100,
         "2020-08-05T09:30:00Z",
         "160.620000000000000000"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "trade_dt",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "symbol",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "exchange",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "event_tm",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "event_seq_nb",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "arrival_tm",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "trade_pr",
         "type": "\"decimal(38,18)\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(trade.select(\"*\").tail(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "203d6efa-5104-4435-9a16-f589057da1bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------+--------+------------+----------+--------+\n",
      "|trade_dt|symbol|exchange|event_tm|event_seq_nb|arrival_tm|trade_pr|\n",
      "+--------+------+--------+--------+------------+----------+--------+\n",
      "+--------+------+--------+--------+------------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each unique identifier\n",
    "duplicate_counts = trade.groupBy(\n",
    "    \"trade_dt\", \"symbol\", \"exchange\", \"event_tm\", \"event_seq_nb\"\n",
    ").agg(count(\"arrival_tm\").alias(\"count\"))\n",
    "\n",
    "# Keep only identifiers that have multiple occurrences (more than 1)\n",
    "duplicates_only = duplicate_counts.filter(col(\"count\") > 1).drop(\"count\")\n",
    "\n",
    "# Join back to the original DataFrame to filter only these duplicate rows\n",
    "trade_duplicates = trade.join(\n",
    "    duplicates_only,\n",
    "    on=[\"trade_dt\", \"symbol\", \"exchange\", \"event_tm\", \"event_seq_nb\"],\n",
    "    how=\"inner\"\n",
    ").orderBy(\"trade_dt\", \"symbol\", \"exchange\", \"event_tm\", \"event_seq_nb\", \"arrival_tm\")\n",
    "\n",
    "# Show duplicate rows with different arrival_tm\n",
    "trade_duplicates.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3384d758-94e3-455c-95ce-ead5d7b37a00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------+-----------------------+------------+-------------------+--------+\n",
      "|trade_dt  |symbol|exchange|event_tm               |event_seq_nb|arrival_tm         |trade_pr|\n",
      "+----------+------+--------+-----------------------+------------+-------------------+--------+\n",
      "|2020-08-06|SYMA  |NYSE    |2020-08-06 10:49:37.345|10          |2020-08-06 09:30:00|74.49   |\n",
      "|2020-08-06|SYMA  |NYSE    |2020-08-06 12:00:11.545|20          |2020-08-06 09:30:00|76.16   |\n",
      "|2020-08-06|SYMA  |NYSE    |2020-08-06 13:11:57.308|30          |2020-08-06 09:30:00|76.90   |\n",
      "|2020-08-06|SYMA  |NYSE    |2020-08-06 14:27:13.014|40          |2020-08-06 09:30:00|77.12   |\n",
      "|2020-08-06|SYMA  |NYSE    |2020-08-06 15:39:08.521|50          |2020-08-06 09:30:00|76.37   |\n",
      "|2020-08-06|SYMA  |NYSE    |2020-08-06 16:58:58.633|60          |2020-08-06 09:30:00|78.32   |\n",
      "|2020-08-06|SYMA  |NYSE    |2020-08-06 18:14:28.899|70          |2020-08-06 09:30:00|78.23   |\n",
      "|2020-08-06|SYMA  |NYSE    |2020-08-06 19:28:22.629|80          |2020-08-06 09:30:00|76.53   |\n",
      "|2020-08-06|SYMA  |NYSE    |2020-08-06 20:49:10.946|90          |2020-08-06 09:30:00|75.71   |\n",
      "|2020-08-06|SYMA  |NYSE    |2020-08-06 22:00:18.406|100         |2020-08-06 09:30:00|76.31   |\n",
      "|2020-08-06|SYMB  |NYSE    |2020-08-06 10:45:42.992|10          |2020-08-06 09:30:00|33.86   |\n",
      "|2020-08-06|SYMB  |NYSE    |2020-08-06 12:01:40.839|20          |2020-08-06 09:30:00|32.93   |\n",
      "|2020-08-06|SYMB  |NYSE    |2020-08-06 13:13:27.041|30          |2020-08-06 09:30:00|33.69   |\n",
      "|2020-08-06|SYMB  |NYSE    |2020-08-06 14:29:42.34 |40          |2020-08-06 09:30:00|35.07   |\n",
      "|2020-08-06|SYMB  |NYSE    |2020-08-06 15:46:21.701|50          |2020-08-06 09:30:00|34.83   |\n",
      "|2020-08-06|SYMB  |NYSE    |2020-08-06 16:57:15.217|60          |2020-08-06 09:30:00|33.32   |\n",
      "|2020-08-06|SYMB  |NYSE    |2020-08-06 18:06:29.531|70          |2020-08-06 09:30:00|33.57   |\n",
      "|2020-08-06|SYMB  |NYSE    |2020-08-06 19:21:50.111|80          |2020-08-06 09:30:00|33.11   |\n",
      "|2020-08-06|SYMB  |NYSE    |2020-08-06 20:36:05.757|90          |2020-08-06 09:30:00|32.64   |\n",
      "|2020-08-06|SYMB  |NYSE    |2020-08-06 21:46:00.523|100         |2020-08-06 09:30:00|35.92   |\n",
      "+----------+------+--------+-----------------------+------------+-------------------+--------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "3.1.3 Apply Data Correction\n",
    "In the exchange dataset, you can uniquely identify a record by the combination of trade_dt,\n",
    "symbol, exchange, event_tm, event_seq_nb. However, the exchange may correct an error in\n",
    "any submitted record by sending a new record with the same uniqueID. Such records will come\n",
    "with later arrival_tm. You must ensure you only accept the one with the most recent arrival_tm.\n",
    "This operation requires aggregation in order to group the dataset by their unique ID, so that a\n",
    "single function can be applied to a certain group entirely. In Spark, we use groupBy operation to\n",
    "achieve this.\n",
    "'''\n",
    "def applyLatest_groupby(df):\n",
    "    # Step 1: Get the latest arrival_tm for each unique record\n",
    "    latest_arrival = df.groupBy(\n",
    "        \"trade_dt\", \"symbol\", \"exchange\", \"event_tm\", \"event_seq_nb\"\n",
    "    ).agg(max(\"arrival_tm\").alias(\"latest_arrival_tm\"))\n",
    "\n",
    "    # Step 2: Filter records that match the latest arrival_tm in the original DataFrame\n",
    "    df_filtered = df.join(\n",
    "        latest_arrival,\n",
    "        on=[\"trade_dt\", \"symbol\", \"exchange\", \"event_tm\", \"event_seq_nb\"],\n",
    "        how=\"inner\"\n",
    "    ).filter(col(\"arrival_tm\") == col(\"latest_arrival_tm\")).drop(\"latest_arrival_tm\")\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "# Apply function to the trade DataFrame\n",
    "trade_corrected = applyLatest_groupby(trade)\n",
    "\n",
    "# Show results\n",
    "trade_corrected.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "668808f7-10a8-4225-97b5-60aaed598031",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "# Define the function using groupBy()\n",
    "def applyLatest_groupby(df):\n",
    "    # Step 1: Get the latest arrival_tm for each unique record\n",
    "    latest_arrival = df.groupBy(\n",
    "        \"trade_dt\", \"symbol\", \"exchange\", \"event_tm\", \"event_seq_nb\"\n",
    "    ).agg(max(\"arrival_tm\").alias(\"latest_arrival_tm\"))\n",
    "\n",
    "    # Step 2: Join back to the original dataset to keep only the latest records\n",
    "    df_latest = (\n",
    "        df.alias(\"d\")\n",
    "        .join(\n",
    "            latest_arrival.alias(\"l\"),\n",
    "            (col(\"d.trade_dt\") == col(\"l.trade_dt\")) &\n",
    "            (col(\"d.symbol\") == col(\"l.symbol\")) &\n",
    "            (col(\"d.exchange\") == col(\"l.exchange\")) &\n",
    "            (col(\"d.event_tm\") == col(\"l.event_tm\")) &\n",
    "            (col(\"d.event_seq_nb\") == col(\"l.event_seq_nb\")) &\n",
    "            (col(\"d.arrival_tm\") == col(\"l.latest_arrival_tm\")),\n",
    "            \"inner\"\n",
    "        )\n",
    "        .select(\"d.*\")  # Select only columns from the original DataFrame\n",
    "    )\n",
    "\n",
    "    return df_latest\n",
    "# Assuming `trade` is already a DataFrame\n",
    "trade_corrected = applyLatest_groupby(trade)\n",
    "\n",
    "\n",
    "# Show results\n",
    "#trade_corrected.show(truncate=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b66e0523-72f5-4148-9985-4b664d394d56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''from pyspark.sql.functions import col, max\n",
    "from pyspark.sql.window import Window \n",
    "\n",
    "# [implement “applyLatest” method to dataframe trade]\n",
    "def applyLatest(df):\n",
    "    return (\n",
    "        df.withColumn(\"rank\", max(\"arrival_tm\").over(\n",
    "            Window.partitionBy(\"trade_dt\", \"symbol\", \"exchange\", \"event_tm\", \"event_seq_nb\")\n",
    "        ))\n",
    "        .filter(col(\"rank\") == col(\"arrival_tm\"))\n",
    "        .drop(\"rank\")\n",
    "    )\n",
    "\n",
    "# Apply correction\n",
    "trade_corrected_partitionby = applyLatest(trade)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d7b00c8-8cd3-430f-8959-7e6ed291869c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trade_dt', 'date'),\n",
       " ('symbol', 'string'),\n",
       " ('exchange', 'string'),\n",
       " ('event_tm', 'timestamp'),\n",
       " ('event_seq_nb', 'int'),\n",
       " ('arrival_tm', 'timestamp'),\n",
       " ('trade_pr', 'decimal(10,2)')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_corrected.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "30545010-e315-404e-92e3-2297bda88541",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are DataFrames Identical? True\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def compare_dataframes(df1, df2):\n",
    "    return df1.exceptAll(df2).count() == 0 and df2.exceptAll(df1).count() == 0\n",
    "\n",
    "# Example Usage\n",
    "are_equal = compare_dataframes(trade_corrected, trade_corrected_partitionby)\n",
    "\n",
    "print(f\"Are DataFrames Identical? {are_equal}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fef77f04-ce97-48c3-bd06-476e3da81cd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17a505d9-14ae-4439-ae77-522e7d9f0d7a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "rade"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_corrected.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1acee6e-bda0-4bd6-8eff-036b69f82c85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet files written successfully for trade dates: ['2020-08-06', '2020-08-05']\n"
     ]
    }
   ],
   "source": [
    "# 3.1.4 Write The Trade Dataset Back To Parquet On Azure Blob Storage\n",
    "# Define trade dates\n",
    "trade_dates = [\"2020-08-06\", \"2020-08-05\"]\n",
    "\n",
    "# Write each trade dataset back to Parquet on Azure Blob Storage\n",
    "for trade_date in trade_dates:\n",
    "    trade_corrected.filter(f\"trade_dt = '{trade_date}'\") \\\n",
    "        .write.mode('append') \\\n",
    "        .parquet(f\"wasbs://equity-data@trial25.blob.core.windows.net/trade/trade_dt={trade_date}\")\n",
    "\n",
    "print(\"Parquet files written successfully for trade dates:\", trade_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42b6e2a3-a651-41e4-8842-092cd99a99ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3.2 Populate Quote dataset using the same method\n",
    "quote_location = \"wasbs://equity-data@trial25.blob.core.windows.net/output_dir/partition=Q\"\n",
    "quote_common = spark.read.parquet(quote_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b652d01-c190-4fe4-a195-aae61e160f38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3.1.2 Select The Necessary Columns For Quote Records\n",
    "quote = quote_common.select(\"trade_dt\", \"symbol\", \"exchange\", \"event_tm\",\n",
    "\"event_seq_nb\",\"arrival_tm\",\"bid_pr\",\"bid_size\",\"ask_pr\",\"ask_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32df0f0d-17ed-47ff-85a6-b0a64b69deb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|         arrival_tm|\n",
      "+-------------------+\n",
      "|2020-08-06 09:30:00|\n",
      "|2020-08-05 09:30:00|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "quote.select(\"arrival_tm\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9e32cdf-4369-4cff-9bfb-361bb5916d01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------+--------+------------+----------+------+--------+------+--------+\n",
      "|trade_dt|symbol|exchange|event_tm|event_seq_nb|arrival_tm|bid_pr|bid_size|ask_pr|ask_size|\n",
      "+--------+------+--------+--------+------------+----------+------+--------+------+--------+\n",
      "+--------+------+--------+--------+------------+----------+------+--------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each unique identifier\n",
    "duplicate_counts = quote.groupBy(\n",
    "    \"trade_dt\", \"symbol\", \"exchange\", \"event_tm\", \"event_seq_nb\"\n",
    ").agg(count(\"arrival_tm\").alias(\"count\"))\n",
    "\n",
    "# Keep only identifiers that have multiple occurrences (more than 1)\n",
    "duplicates_only = duplicate_counts.filter(col(\"count\") > 1).drop(\"count\")\n",
    "\n",
    "# Join back to the original DataFrame to filter only these duplicate rows\n",
    "quote_duplicates = quote.join(\n",
    "    duplicates_only,\n",
    "    on=[\"trade_dt\", \"symbol\", \"exchange\", \"event_tm\", \"event_seq_nb\"],\n",
    "    how=\"inner\"\n",
    ").orderBy(\"trade_dt\", \"symbol\", \"exchange\", \"event_tm\", \"event_seq_nb\", \"arrival_tm\")\n",
    "\n",
    "# Show duplicate rows with different arrival_tm\n",
    "quote_duplicates.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba2c4226-83c8-473e-9191-27df0201e5c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------+-----------------------+------------+-------------------+------+--------+------+--------+\n",
      "|trade_dt  |symbol|exchange|event_tm               |event_seq_nb|arrival_tm         |bid_pr|bid_size|ask_pr|ask_size|\n",
      "+----------+------+--------+-----------------------+------------+-------------------+------+--------+------+--------+\n",
      "|2020-08-06|SYMB  |NYSE    |2020-08-06 21:31:19.68 |98          |2020-08-06 09:30:00|36.36 |100     |37.98 |100     |\n",
      "|2020-08-06|SYMB  |NYSE    |2020-08-06 21:36:50.686|99          |2020-08-06 09:30:00|36.18 |100     |37.41 |100     |\n",
      "|2020-08-06|SYMB  |NYSE    |2020-08-06 14:24:39.65 |39          |2020-08-06 09:30:00|31.95 |100     |33.67 |100     |\n",
      "|2020-08-06|SYMB  |NYSE    |2020-08-06 12:09:32.442|21          |2020-08-06 09:30:00|34.83 |100     |36.23 |100     |\n",
      "|2020-08-06|SYMC  |NYSE    |2020-08-06 11:34:20.858|17          |2020-08-06 09:30:00|161.31|100     |163.21|100     |\n",
      "|2020-08-06|SYMA  |NYSE    |2020-08-06 16:33:46.316|57          |2020-08-06 09:30:00|75.56 |100     |75.81 |100     |\n",
      "|2020-08-06|SYMA  |NYSE    |2020-08-06 16:22:09.718|55          |2020-08-06 09:30:00|79.21 |100     |80.53 |100     |\n",
      "|2020-08-06|SYMA  |NYSE    |2020-08-06 21:04:40.263|92          |2020-08-06 09:30:00|75.75 |100     |77.67 |100     |\n",
      "|2020-08-06|SYMB  |NYSE    |2020-08-06 12:36:02.016|25          |2020-08-06 09:30:00|35.15 |100     |35.73 |100     |\n",
      "|2020-08-06|SYMC  |NYSE    |2020-08-06 20:46:57.338|94          |2020-08-06 09:30:00|158.43|100     |159.29|100     |\n",
      "|2020-08-06|SYMA  |NYSE    |2020-08-06 09:56:26.402|3           |2020-08-06 09:30:00|75.12 |100     |75.39 |100     |\n",
      "|2020-08-06|SYMC  |NYSE    |2020-08-06 15:54:39.028|55          |2020-08-06 09:30:00|156.91|100     |157.28|100     |\n",
      "|2020-08-06|SYMA  |NYSE    |2020-08-06 12:18:22.965|22          |2020-08-06 09:30:00|76.77 |100     |78.56 |100     |\n",
      "|2020-08-06|SYMB  |NYSE    |2020-08-06 11:39:25.984|17          |2020-08-06 09:30:00|35.64 |100     |36.78 |100     |\n",
      "|2020-08-06|SYMC  |NYSE    |2020-08-06 11:18:10.671|15          |2020-08-06 09:30:00|158.64|100     |159.96|100     |\n",
      "|2020-08-06|SYMA  |NYSE    |2020-08-06 16:04:09.571|53          |2020-08-06 09:30:00|77.49 |100     |78.93 |100     |\n",
      "|2020-08-06|SYMC  |NYSE    |2020-08-06 14:22:04.238|41          |2020-08-06 09:30:00|157.95|100     |158.17|100     |\n",
      "|2020-08-06|SYMC  |NYSE    |2020-08-06 21:09:21.713|97          |2020-08-06 09:30:00|158.72|100     |159.18|100     |\n",
      "|2020-08-06|SYMB  |NYSE    |2020-08-06 09:45:57.819|2           |2020-08-06 09:30:00|32.85 |100     |33.09 |100     |\n",
      "|2020-08-06|SYMA  |NYSE    |2020-08-06 11:12:25.921|13          |2020-08-06 09:30:00|75.01 |100     |75.33 |100     |\n",
      "+----------+------+--------+-----------------------+------------+-------------------+------+--------+------+--------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Apply function to the quote DataFrame\n",
    "quote_corrected = applyLatest_groupby(quote)\n",
    "\n",
    "# Show results\n",
    "quote_corrected.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af34a2a3-7326-4eb8-ae67-358a66d1d28f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3.2.4 Write The Quote Dataset Back To Parquet On Azure Blob Storage\n",
    "# Define quote dates\n",
    "quote_dates = [\"2020-08-06\", \"2020-08-05\"]\n",
    "\n",
    "# Write each quote dataset back to Parquet on Azure Blob Storage\n",
    "for quote_date in quote_dates:\n",
    "    quote_corrected.filter(f\"quote_dt = '{quote_date}'\") \\\n",
    "        .write.mode('append') \\\n",
    "        .parquet(f\"wasbs://equity-data@trial25.blob.core.windows.net/quote/quote_dt={quote_date}\")\n",
    "\n",
    "print(\"Parquet files written successfully for quote dates:\", quote_dates)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "End-of-Day (EOD) Data Load",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
